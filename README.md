# Search-Engine-in-Python
Beautiful Soup, Sklearn, Crawler, Vector space model
The code takes a user's search query as input. It crawls the web portal using the query, extracts publication data, and stocks it in a list of dictionaries. The crawling process repeats for multiple pages of search results. The crawled data is pre-processed (capitalization, lowercase conversion) and then ranked using the Vector Space Model (TF-IDF) based on the user's query to retrieve the most relevant publications. The top 10 ranked publications are displayed.
The code maintains a dictionary called staff_publication_count to keep track of the number of publications made by each staff member. It raises the count for each publication connected to a writer (staff member) during the crawling procedure. The number of staff members whose publications are crawled can be calculated using the length of this dictionary (len(staff_publication_count)). The information gotten about each publication includes Title, Authors (multiple authors are concatenated with commas), Publisher, Publication status, Publication page link, CGL author link (URL to the author's profile). 
The pre-processing tasks performed on output are making the first letter of each word in the title capital, Removing leading/trailing whitespaces from author names. Changing publisher names to lowercase. The code runs the crawler and display the results. Also, it has a schedle_crawl() function that uses a scheduler to crawl the publications periodically (every one week or 604,800 seconds).
